# AI Provider Configuration
# Options: openai, anthropic, local
AI_PROVIDER=anthropic

# API Keys (for cloud providers)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI Configuration
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.1

# Anthropic Configuration
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_MAX_TOKENS=4000
ANTHROPIC_TEMPERATURE=0.1

# Local LLM Configuration (Ollama)
LOCAL_LLM_URL=http://localhost:11434
LOCAL_LLM_MODEL=llama3:8b
LOCAL_LLM_MAX_TOKENS=4000
LOCAL_LLM_TEMPERATURE=0.1

# Application Settings
OUTPUT_DIR=./data/outputs
CACHE_DIR=./data/cache
ENABLE_CACHE=true
MAX_RETRIES=3
LOG_LEVEL=INFO

# Compliance Standard
COMPLIANCE_STANDARD=CCE
